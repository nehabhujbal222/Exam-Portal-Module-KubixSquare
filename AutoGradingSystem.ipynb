{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoGradingSystem.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCmM8jwrWT_W"
      },
      "source": [
        "# **Introduction**\n",
        "\n",
        "This project provides a great start to build your own auto-grading system. It aims to cut the tedious hours spent in correcting the answers of students on tests/exams. The proposed module presents the final grade attained on any given test within seconds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiLXYKrXAfUz"
      },
      "source": [
        "## **Installing necessary Packages**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX7fWeDbz_UM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94405f5e-34d7-4390-9a89-2a45902b9c2d"
      },
      "source": [
        "!pip install nltk "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nidYCG_m3qk6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5adece45-9b45-4436-d524-6cd3d905cb10"
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (4.1.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpPqrr2hGZaG"
      },
      "source": [
        "## **Importing necessary Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK0Xlpf51oHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83906e31-de00-4ee5-b0d4-7060684ea5d3"
      },
      "source": [
        "import nltk\n",
        "import gensim\n",
        "import numpy as np\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UZ5J6251LR8"
      },
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MloU8_XsL_hN"
      },
      "source": [
        "**Tokenization** is a necessary first step in many NLP tasks (word counting, corpus generation, spell check, etc) \n",
        "\n",
        "The method **word_tokenize()** is use to split the sentence into words as shown in the example below. Similiarly, **sent_tokenize** is used to split two or more sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USkXamdMA6EQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518e4307-981e-49da-859d-b2c702a47b5e"
      },
      "source": [
        "data = \"i am an indian\"\n",
        "print(word_tokenize(data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'am', 'an', 'indian']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMdZrpOnAYRA"
      },
      "source": [
        "## **Sample Text Files**\n",
        "\n",
        "**Note:** These files are created only for the simplicity of testing purpose. The user is expected to attach the respective text files for **Correct Answer** and **Students' Answers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "espd-sI2yAGB"
      },
      "source": [
        " #creating txt sample for correct answer\n",
        "\n",
        "with open('predicted_answers.txt', 'w') as writefile:\n",
        "  writefile.write(\"Saturn is yellow planet.\")\n",
        "  writefile.write(\"\\nMars is the second smallest planet in our Solar system.\")\n",
        "  writefile.write(\"\\nSaturn is the sixth planet from the Sun.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcqIEtNdwZFf"
      },
      "source": [
        "#creating txt Sample 1 for students' answer\n",
        "\n",
        "with open('student_answers.txt', 'w') as writefile:\n",
        "  writefile.write(\"Mars is the fourth planet in our solar system.\")\n",
        "  writefile.write(\"\\nIt is second-smallest planet in the Solar System after Mercury.\")\n",
        "  writefile.write(\"\\nSaturn is yellow planet.\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee4OdJoizWUz"
      },
      "source": [
        "#creating txt Sample 2 for students' answer\n",
        "\n",
        "with open('predicted_answers.txt', 'w') as writefile:\n",
        "  writefile.write(\"Mars is the second smallest planet in our Solar system.\")\n",
        "  writefile.write(\"\\nSaturn is the sixth planet from the Sun.\")\n",
        "  writefile.write(\"\\nSaturn is yellow planet.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svsLemQ85HBc"
      },
      "source": [
        "## **Tokenization of student answers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8QwxuqUMP5R"
      },
      "source": [
        "**Step 1:** Splitting different answers using sent_tokenize()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDzuC1FCzFUz"
      },
      "source": [
        "ans_doc= []\n",
        "\n",
        "with open('student_answers.txt') as f:\n",
        "  tokens= sent_tokenize(f.read())\n",
        "  for line in tokens:\n",
        "    ans_doc.append(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EysD3V_210NN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d31608f9-17e2-452c-e17b-0992fa30dab2"
      },
      "source": [
        "print(ans_doc)\n",
        "print(\"\\nTotal number of answers: \", len(ans_doc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Mars is the fourth planet in our solar system.', 'It is second-smallest planet in the Solar System after Mercury.', 'Saturn is yellow planet.']\n",
            "\n",
            "Total number of answers:  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNGJ_STQMuCF"
      },
      "source": [
        "**Step 2:** Tokenizing answer words to create a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_LCyRPY15pp"
      },
      "source": [
        "ans_dict = [[w.lower() for w in word_tokenize(text)] \n",
        "            for text in ans_doc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsfvKLTG5-BR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e59c04-2937-4f16-b54e-dfc4c9fa9119"
      },
      "source": [
        "print(ans_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['mars', 'is', 'the', 'fourth', 'planet', 'in', 'our', 'solar', 'system', '.'], ['it', 'is', 'second-smallest', 'planet', 'in', 'the', 'solar', 'system', 'after', 'mercury', '.'], ['saturn', 'is', 'yellow', 'planet', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObIyDpn_M8hf"
      },
      "source": [
        "**Step 3:** Giving Unique ID to each word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh8L1M5h6C08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5936c958-8db4-4d5a-addd-d3d33949918a"
      },
      "source": [
        "ans_id = gensim.corpora.Dictionary(ans_dict)\n",
        "print(ans_id.token2id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'.': 0, 'fourth': 1, 'in': 2, 'is': 3, 'mars': 4, 'our': 5, 'planet': 6, 'solar': 7, 'system': 8, 'the': 9, 'after': 10, 'it': 11, 'mercury': 12, 'second-smallest': 13, 'saturn': 14, 'yellow': 15}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUp3B2vONKZI"
      },
      "source": [
        "**Step 4:** Creating a bag of words. \n",
        "It assigns frequency of words at each index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9WzczRh7syg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06bfa3a8-ea94-4169-8cd0-7aba7bb5b944"
      },
      "source": [
        "ans_corpus= [ans_id.doc2bow(a) for a in ans_dict]\n",
        "print(ans_corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1)], [(0, 1), (2, 1), (3, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1)], [(0, 1), (3, 1), (6, 1), (14, 1), (15, 1)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjbTimG6Nled"
      },
      "source": [
        "**Step 5:** TFIDF-\n",
        "Assign weights to words. The higher the frequecny, lower is the weight."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWaZSHTv9ksn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44e9bc44-923f-4fd4-ee67-28192ea6df3d"
      },
      "source": [
        "tf_idf1 = gensim.models.TfidfModel(ans_corpus)\n",
        "\n",
        "for doc in tf_idf1[ans_corpus]:\n",
        "    print([[ans_id[id], np.around(freq, decimals=2)] for id, freq in doc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['fourth', 0.53], ['in', 0.2], ['mars', 0.53], ['our', 0.53], ['solar', 0.2], ['system', 0.2], ['the', 0.2]]\n",
            "[['in', 0.17], ['solar', 0.17], ['system', 0.17], ['the', 0.17], ['after', 0.47], ['it', 0.47], ['mercury', 0.47], ['second-smallest', 0.47]]\n",
            "[['saturn', 0.71], ['yellow', 0.71]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WwTM2Zfk1zn"
      },
      "source": [
        "## **Sentence Tokenization of Predicted Answers (correct)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKgqTh6oN8wd"
      },
      "source": [
        "**Step 1:** Splitting answers of the student based on different questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnMBLyaqk7Ao"
      },
      "source": [
        "pred_doc= []\n",
        "\n",
        "with open('predicted_answers.txt') as f:\n",
        "  tokens= sent_tokenize(f.read())\n",
        "  for line in tokens:\n",
        "    pred_doc.append(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nioWt0clLEB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3fc1f1-ffc6-48ee-fde5-ccf8b18c425d"
      },
      "source": [
        "print(pred_doc)\n",
        "print(\"\\nTotal number of answers: \", len(pred_doc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Saturn is yellow planet.', 'Mars is the second smallest planet in our Solar system.', 'Saturn is the sixth planet from the Sun.']\n",
            "\n",
            "Total number of answers:  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL0V0EghhbLX"
      },
      "source": [
        "## **Checking Similarity**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hGUzePgQ_IE"
      },
      "source": [
        "**Creating Similarity object:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhLJK04owVn9"
      },
      "source": [
        "sims = gensim.similarities.Similarity('sample_data/',tf_idf1[ans_corpus],num_features=len(ans_id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K6nyZRBRKZ2"
      },
      "source": [
        "**Similarity Algorithm:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecp-lket__EE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5abc3a6b-9478-466d-b717-54e7a34058ee"
      },
      "source": [
        "arr=[]\n",
        "for line in pred_doc:\n",
        "    pred= [w.lower() for w in word_tokenize(line)]\n",
        "    pred_corpus = ans_id.doc2bow(pred)\n",
        "    print(\"Tokenized words for predicted ans:\\n\",pred)\n",
        "    print(\"Bag of Words with frequency:\\n\",pred_corpus)\n",
        "    pred_tfidf= tf_idf1[pred_corpus]\n",
        "    print(\"Similarity:\",sims[pred_tfidf],\"\\n\")\n",
        "    arr.append(sims[pred_tfidf])\n",
        "print(arr)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized words for predicted ans:\n",
            " ['saturn', 'is', 'yellow', 'planet', '.']\n",
            "Bag of Words with frequency:\n",
            " [(0, 1), (3, 1), (6, 1), (14, 1), (15, 1)]\n",
            "Similarity: [0.         0.         0.99999994] \n",
            "\n",
            "Tokenized words for predicted ans:\n",
            " ['mars', 'is', 'the', 'second', 'smallest', 'planet', 'in', 'our', 'solar', 'system', '.']\n",
            "Bag of Words with frequency:\n",
            " [(0, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1)]\n",
            "Similarity: [0.8472902  0.16020904 0.        ] \n",
            "\n",
            "Tokenized words for predicted ans:\n",
            " ['saturn', 'is', 'the', 'sixth', 'planet', 'from', 'the', 'sun', '.']\n",
            "Bag of Words with frequency:\n",
            " [(0, 1), (3, 1), (6, 1), (9, 2), (14, 1)]\n",
            "Similarity: [0.11641413 0.10281226 0.56890744] \n",
            "\n",
            "[array([0.        , 0.        , 0.99999994], dtype=float32), array([0.8472902 , 0.16020904, 0.        ], dtype=float32), array([0.11641413, 0.10281226, 0.56890744], dtype=float32)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/similarities/docsim.py:518: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  result = numpy.hstack(shard_results)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C6ERKgHIPvK"
      },
      "source": [
        "## **Final Grade**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3Vl0U46QExx"
      },
      "source": [
        "**Finding the Average Similarity of answers:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRsjtWr8Py6k",
        "outputId": "1422445c-f50b-4aa1-bea4-bc13a4ade49b"
      },
      "source": [
        "temp = 0\n",
        "for i in range(len(arr)):\n",
        "  for j in range(len(arr)):\n",
        "    if i==j:\n",
        "      temp+= arr[i][i]\n",
        "\n",
        "avg_similarity= temp/len(arr)\n",
        "print(\"Average Similarity= \",avg_similarity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Similarity=  0.24303882817427316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlvB0mU8QRSV"
      },
      "source": [
        "**Similarity in terms of percentage:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjHOXkDHB1Ku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a167149-9228-4a98-a104-89d0259f92b8"
      },
      "source": [
        "perc_similarity= round(avg_similarity * 100)\n",
        "print(perc_similarity,\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILwgWQACUlqg"
      },
      "source": [
        "**Evaluation of Final Score:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T4OUcw6S_Ay",
        "outputId": "bcb993c3-9a03-4093-e682-56fae9d8168d"
      },
      "source": [
        "max_marks= int(input(\"Enter the maximum attainable marks on this test: \"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the maximum attainable marks on this test: 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfXW2VlgTSBY",
        "outputId": "3a54410c-1618-4fc7-8fd8-d4895ded179b"
      },
      "source": [
        "student_score = (perc_similarity/100) * 50\n",
        "print(\"The final score is \", student_score, \"/\", max_marks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The final score is  12.0 / 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aif_Tqjdd4Ng"
      },
      "source": [
        "## **CSV for taking input answers**\n",
        "Additional section which provides a medium to get input answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29AfHrs8eMhy"
      },
      "source": [
        "# Creating CSV\n",
        "import csv\n",
        "\n",
        "with open('answers.csv', 'w') as csvfile:\n",
        "    filewriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "    filewriter.writerow(['Answer'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwUkuF0YmIwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "419a9346-32e2-404d-cf12-2200d268af4c"
      },
      "source": [
        "# Taking input from user for answers\n",
        "ans1 = input()\n",
        "with open('answers.csv', 'a') as f:\n",
        "    writer = csv.writer(f)\n",
        "    # the input answers will be saved as each line in one cell of the same row.\n",
        "    writer.writerow(ans1.splitlines( ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi, this is the first sample answer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8mNUd6zquXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17be5569-8093-4185-9107-edcd5a0325b9"
      },
      "source": [
        "# Displaying the contents of answer.csv file\n",
        "f = open('answers.csv', 'r')\n",
        "if f.mode == 'r':\n",
        "    contents = f.read()\n",
        "print(contents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Answer\n",
            "\"Hi, this is the first sample answer\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWfGZP_8VVZJ"
      },
      "source": [
        "# **Future Work**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl81_klJVdr6"
      },
      "source": [
        "The proposed module will prove to be a great helping hand in the educational domain. It has huge scope for future development as is discussed in this section. \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Here are some points that can be considered to further optimize this project:\n",
        "\n",
        "\n",
        "1.   **Prediction of correct answers:** The proposed algorithm requires the user to provide a file consisting of correct answers. Instead what if the algorithm could itself predict the coorect answer and then evaluate the results? This would further automate the entire process.\n",
        "\n",
        "2. **Convert handwritten answers to text:** Ideally the answers will handwritten by the student will be evaluated with the help of NLP techniques \n",
        "\n",
        "3.   **Designing an Interactive UI:** Web app or mobile app for ease of use to appear for tests and get instant results and performance feedback\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}